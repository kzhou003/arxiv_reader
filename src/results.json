[{"title": "The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development", "abstract": "Systematic literature reviews are the highest quality of evidence in research. However, the review process is hindered by significant resource and data constraints. The Literature Review Network (LRN) is the first of its kind explainable AI platform adhering to PRISMA 2020 standards, designed to automate the entire literature review process. LRN was evaluated in the domain of surgical glove practices using 3 search strings developed by experts to query PubMed. A non-expert trained all LRN models. Performance was benchmarked against an expert manual review. Explainability and performance metrics assessed LRN's ability to replicate the experts' review. Concordance was measured with the Jaccard index and confusion matrices. Researchers were blinded to the other's results until study completion. Overlapping studies were integrated into an LRN-generated systematic review. LRN models demonstrated superior classification accuracy without expert training, achieving 84.78% and 85.71% accuracy. The highest performance model achieved high interrater reliability (k = 0.4953) and explainability metrics, linking 'reduce', 'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51% of the relevant literature despite diverging from the non-expert's judgments (k = 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN outperformed the manual review (19,920 minutes over 11 months), reducing the entire process to 288.6 minutes over 5 days. This study demonstrates that explainable AI does not require expert training to successfully conduct PRISMA-compliant systematic literature reviews like an expert. LRN summarized the results of surgical glove studies and identified themes that were nearly identical to the clinical researchers' findings. Explainable AI can accurately expedite our understanding of clinical practices, potentially revolutionizing healthcare research.", "url": "https://arxiv.org/abs/2408.05239", "authors": "Joshua Morriss, Tod Brindle, Jessica Bah R\u00f6sman, Daniel Reibsamen, Andreas Enz", "subjects": "Digital Libraries (cs.DL); Artificial Intelligence (cs.AI)", "pdf_url": "https://arxiv.org/pdf/2408.05239", "relevancy_score": 9, "reasons_for_match": "This paper introduces the Literature Review Network (LRN), an explainable AI platform for automating literature reviews, which aligns with your interest in artificial intelligence and computer science."}, {"title": "The Role and Applications of Airport Digital Twin in Cyberattack Protection during the Generative AI Era", "abstract": "In recent years, the threat facing airports from growing and increasingly sophisticated cyberattacks has become evident. Airports are considered a strategic national asset, so protecting them from attacks, specifically cyberattacks, is a crucial mission. One way to increase airports' security is by using Digital Twins (DTs). This paper shows and demonstrates how DTs can enhance the security mission. The integration of DTs with Generative AI (GenAI) algorithms can lead to synergy and new frontiers in fighting cyberattacks. The paper exemplifies ways to model cyberattack scenarios using simulations and generate synthetic data for testing defenses. It also discusses how DTs can be used as a crucial tool for vulnerability assessment by identifying weaknesses, prioritizing, and accelerating remediations in case of cyberattacks. Moreover, the paper demonstrates approaches for anomaly detection and threat hunting using Machine Learning (ML) and GenAI algorithms. Additionally, the paper provides impact prediction and recovery coordination methods that can be used by DT operators and stakeholders. It also introduces ways to harness the human factor by integrating training and simulation algorithms with Explainable AI (XAI) into the DT platforms. Lastly, the paper offers future applications and technologies that can be utilized in DT environments.", "url": "https://arxiv.org/abs/2408.05248", "authors": "Abraham Itzhak Weinberg", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "pdf_url": "https://arxiv.org/pdf/2408.05248", "relevancy_score": 9, "reasons_for_match": "This paper explores the role of Digital Twins (DTs) in enhancing airport security, specifically in the context of cyberattacks. It discusses the integration of DTs with Generative AI (GenAI) algorithms, simulation modeling of cyberattack scenarios, anomaly detection, and threat hunting using Machine Learning (ML) and GenAI algorithms, as well as impact prediction and recovery coordination methods. This aligns with your interests in Artificial Intelligence and has direct applications in computer science."}, {"title": "Large Language Model based Agent Framework for Electric Vehicle Charging Behavior Simulation", "abstract": "This paper introduces a new LLM based agent framework for simulating electric vehicle (EV) charging behavior, integrating user preferences, psychological characteristics, and environmental factors to optimize the charging process. The framework comprises several modules, enabling sophisticated, adaptive simulations. Dynamic decision making is supported by continuous reflection and memory updates, ensuring alignment with user expectations and enhanced efficiency. The framework's ability to generate personalized user profiles and real-time decisions offers significant advancements for urban EV charging management. Future work could focus on incorporating more intricate scenarios and expanding data sources to enhance predictive accuracy and practical utility.", "url": "https://arxiv.org/abs/2408.05233", "authors": "Junkang Feng, Chenggang Cui, Chuanlin Zhang, Zizhu Fan", "subjects": "Artificial Intelligence (cs.AI)", "pdf_url": "https://arxiv.org/pdf/2408.05233", "relevancy_score": 8, "reasons_for_match": "This paper introduces a new agent framework for simulating electric vehicle charging behavior, which aligns with your research interest in artificial intelligence and computer science."}, {"title": "Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models", "abstract": "As the performance of larger, newer Large Language Models continues to improve for strategic Theory of Mind (ToM) tasks, the demand for these state of the art models increases commensurately. However, their deployment is costly both in terms of processing power and time. In this paper, we investigate the feasibility of creating smaller, simulation-ready agents by way of fine-tuning. To do this, we present a large pre-trained model with 20 unique scenarios that combine a social context with a social dilemma, recording its answers, and using them for Q\\&A fine-tuning on a smaller model of the same family. Our focus is on in-context game-theoretic decision-making, the same domain within which human interaction occurs and that requires both a theory of mind (or a semblance thereof) and an understanding of social dynamics. We find that the fine-tuned smaller language model exhibited significant performance closer to that of its larger relative, and that their improvements extended in areas and contexts beyond the ones provided in the training examples. On average for all games, through fine-tuning, the smaller model showed a \\%46 improvement in aligning with the behavior of the larger model, with \\%100 representing complete alignment. This suggests that our pipeline represents an efficient method to transmit some form of theory of mind to smaller models, creating improved and cheaply deployable algorithms in the process. Despite their simplicity and their associated shortcomings and limitations, our findings represent a stepping stone in the pursuit and training of specialized models for strategic and social decision making.", "url": "https://arxiv.org/abs/2408.05241", "authors": "Nunzio Lore, Alireza (Sepehr)Ilami, Babak Heydari", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Emerging Technologies (cs.ET); Computer Science and Game Theory (cs.GT)", "pdf_url": "https://arxiv.org/pdf/2408.05241", "relevancy_score": 8, "reasons_for_match": "This paper explores the feasibility of creating smaller language models through fine-tuning, which is relevant to my interest in efficient algorithms for artificial intelligence."}, {"title": "Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review", "abstract": "Federated Learning (FL) has emerged as a promising solution to address the limitations of centralised machine learning (ML) in oncology, particularly in overcoming privacy concerns and harnessing the power of diverse, multi-center data. This systematic review synthesises current knowledge on the state-of-the-art FL in oncology, focusing on breast, lung, and prostate cancer. Distinct from previous surveys, our comprehensive review critically evaluates the real-world implementation and impact of FL on cancer care, demonstrating its effectiveness in enhancing ML generalisability, performance and data privacy in clinical settings and data. We evaluated state-of-the-art advances in FL, demonstrating its growing adoption amid tightening data privacy regulations. FL outperformed centralised ML in 15 out of the 25 studies reviewed, spanning diverse ML models and clinical applications, and facilitating integration of multi-modal information for precision medicine. Despite the current challenges identified in reproducibility, standardisation and methodology across studies, the demonstrable benefits of FL in harnessing real-world data and addressing clinical needs highlight its significant potential for advancing cancer research. We propose that future research should focus on addressing these limitations and investigating further advanced FL methods, to fully harness data diversity and realise the transformative power of cutting-edge FL in cancer care.", "url": "https://arxiv.org/abs/2408.05249", "authors": "Anshu Ankolekar, Sebastian Boie, Maryam Abdollahyan, Emanuela Gadaleta, Seyed Alireza Hasheminasab, Guang Yang, Charles Beauville, Nikolaos Dikaios, George Anthony Kastis, Michael Bussmann, Sara Khalid, Hagen Kruger, Philippe Lambin, Giorgos Papanastasiou", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Image and Video Processing (eess.IV)", "pdf_url": "https://arxiv.org/pdf/2408.05249", "relevancy_score": 8, "reasons_for_match": "This paper provides a systematic review of the use of Federated Learning (FL) in oncology, specifically in breast, lung, and prostate cancer. It highlights the advantages of FL over centralised machine learning (ML) in terms of privacy concerns and the integration of diverse, multi-center data. The paper demonstrates the effectiveness of FL in enhancing ML generalisability, performance, and data privacy in clinical settings, aligning with your interests in Artificial Intelligence and its applications in computer science."}, {"title": "SLO-aware GPU Frequency Scaling for Energy Efficient LLM Inference Serving", "abstract": "As Large Language Models (LLMs) gain traction, their reliance on power-hungry GPUs places ever-increasing energy demands, raising environmental and monetary concerns. Inference dominates LLM workloads, presenting a critical challenge for providers: minimizing energy costs under Service-Level Objectives (SLOs) that ensure optimal user experience. In this paper, we present \\textit{throttLL'eM}, a framework that reduces energy consumption while meeting SLOs through the use of instance and GPU frequency scaling. \\textit{throttLL'eM} features mechanisms that project future KV cache usage and batch size. Leveraging a Machine-Learning (ML) model that receives these projections as inputs, \\textit{throttLL'eM} manages performance at the iteration level to satisfy SLOs with reduced frequencies and instance sizes. We show that the proposed ML model achieves $R^2$ scores greater than 0.97 and miss-predicts performance by less than 1 iteration per second on average. Experimental results on LLM inference traces show that \\textit{throttLL'eM} achieves up to 43.8\\% lower energy consumption and an energy efficiency improvement of at least $1.71\\times$ under SLOs, when compared to NVIDIA's Triton server.", "url": "https://arxiv.org/abs/2408.05235", "authors": "Andreas Kosmas Kakolyris, Dimosthenis Masouros, Petros Vavaroutsos, Sotirios Xydis, Dimitrios Soudris", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Machine Learning (cs.LG)", "pdf_url": "https://arxiv.org/pdf/2408.05235", "relevancy_score": 7, "reasons_for_match": "This paper presents a framework for reducing energy consumption in Large Language Models (LLMs) while meeting Service-Level Objectives (SLOs), which aligns with your interest in artificial intelligence and computer science."}, {"title": "Improved Adaboost Algorithm for Web Advertisement Click Prediction Based on Long Short-Term Memory Networks", "abstract": "This paper explores an improved Adaboost algorithm based on Long Short-Term Memory Networks (LSTMs), which aims to improve the prediction accuracy of user clicks on web page advertisements. By comparing it with several common machine learning algorithms, the paper analyses the advantages of the new model in ad click prediction. It is shown that the improved algorithm proposed in this paper performs well in user ad click prediction with an accuracy of 92%, which is an improvement of 13.6% compared to the highest of 78.4% among the other three base models. This significant improvement indicates that the algorithm is more capable of capturing user behavioural characteristics and time series patterns. In addition, this paper evaluates the model's performance on other performance metrics, including accuracy, recall, and F1 score. The results show that the improved Adaboost algorithm based on LSTM is significantly ahead of the traditional model in all these metrics, which further validates its effectiveness and superiority. Especially when facing complex and dynamically changing user behaviours, the model is able to better adapt and make accurate predictions. In order to ensure the practicality and reliability of the model, this study also focuses on the accuracy difference between the training set and the test set. After validation, the accuracy of the proposed model on these two datasets only differs by 1.7%, which is a small difference indicating that the model has good generalisation ability and can be effectively applied to real-world scenarios.", "url": "https://arxiv.org/abs/2408.05245", "authors": "Qixuan Yu, Xirui Tang, Feiyang Li, Zinan Cao", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)", "pdf_url": "https://arxiv.org/pdf/2408.05245", "relevancy_score": 7, "reasons_for_match": "This paper proposes an improved Adaboost algorithm based on LSTM for web advertisement click prediction, which is relevant to my interest in machine learning algorithms for AI applications."}, {"title": "Early-Exit meets Model-Distributed Inference at Edge Networks", "abstract": "Distributed inference techniques can be broadly classified into data-distributed and model-distributed schemes. In data-distributed inference (DDI), each worker carries the entire deep neural network (DNN) model but processes only a subset of the data. However, feeding the data to workers results in high communication costs, especially when the data is large. An emerging paradigm is model-distributed inference (MDI), where each worker carries only a subset of DNN layers. In MDI, a source device that has data processes a few layers of DNN and sends the output to a neighboring device, i.e., offloads the rest of the layers. This process ends when all layers are processed in a distributed manner. In this paper, we investigate the design and development of MDI with early-exit, which advocates that there is no need to process all the layers of a model for some data to reach the desired accuracy, i.e., we can exit the model without processing all the layers if target accuracy is reached. We design a framework MDI-Exit that adaptively determines early-exit and offloading policies as well as data admission at the source. Experimental results on a real-life testbed of NVIDIA Nano edge devices show that MDI-Exit processes more data when accuracy is fixed and results in higher accuracy for the fixed data rate.", "url": "https://arxiv.org/abs/2408.05247", "authors": "Marco Colocrese, Erdem Koyuncu, Hulya Seferoglu", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)", "pdf_url": "https://arxiv.org/pdf/2408.05247", "relevancy_score": 7, "reasons_for_match": "This paper explores the design and development of model-distributed inference with early-exit, which is relevant to my interest in efficient algorithms for AI at the edge."}, {"title": "Biomimetic Machine Learning approach for prediction of mechanical properties of Additive Friction Stir Deposited Aluminum alloys based walled structures", "abstract": "This study presents a novel approach to predicting mechanical properties of Additive Friction Stir Deposited (AFSD) aluminum alloy walled structures using biomimetic machine learning. The research combines numerical modeling of the AFSD process with genetic algorithm-optimized machine learning models to predict von Mises stress and logarithmic strain. Finite element analysis was employed to simulate the AFSD process for five aluminum alloys: AA2024, AA5083, AA5086, AA7075, and AA6061, capturing complex thermal and mechanical interactions. A dataset of 200 samples was generated from these simulations. Subsequently, Decision Tree (DT) and Random Forest (RF) regression models, optimized using genetic algorithms, were developed to predict key mechanical properties. The GA-RF model demonstrated superior performance in predicting both von Mises stress (R square = 0.9676) and logarithmic strain (R square = 0.7201). This innovative approach provides a powerful tool for understanding and optimizing the AFSD process across multiple aluminum alloys, offering insights into material behavior under various process parameters.", "url": "https://arxiv.org/abs/2408.05237", "authors": "Akshansh Mishra", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)", "pdf_url": "https://arxiv.org/pdf/2408.05237", "relevancy_score": 6, "reasons_for_match": "This paper presents a machine learning approach for predicting mechanical properties of Additive Friction Stir Deposited (AFSD) aluminum alloy walled structures, which relates to your interest in artificial intelligence and computer science."}, {"title": "Differentially Private Data Release on Graphs: Inefficiencies and Unfairness", "abstract": "Networks are crucial components of many sectors, including telecommunications, healthcare, finance, energy, and transportation.The information carried in such networks often contains sensitive user data, like location data for commuters and packet data for online users. Therefore, when considering data release for networks, one must ensure that data release mechanisms do not leak information about individuals, quantified in a precise mathematical sense. Differential Privacy (DP) is the widely accepted, formal, state-of-the-art technique, which has found use in a variety of real-life settings including the 2020 U.S. Census, Apple users' device data, or Google's location data. Yet, the use of DP comes with new challenges, as the noise added for privacy introduces inaccuracies or biases and further, DP techniques can also distribute these biases disproportionately across different populations, inducing fairness issues. The goal of this paper is to characterize the impact of DP on bias and unfairness in the context of releasing information about networks, taking a departure from previous work which has studied these effects in the context of private population counts release (such as in the U.S. Census). To this end, we consider a network release problem where the network structure is known to all, but the weights on edges must be released privately. We consider the impact of this private release on a simple downstream decision-making task run by a third-party, which is to find the shortest path between any two pairs of nodes and recommend the best route to users. This setting is of highly practical relevance, mirroring scenarios in transportation networks, where preserving privacy while providing accurate routing information is crucial. Our work provides theoretical foundations and empirical evidence into the bias and unfairness arising due to privacy in these networked decision problems.", "url": "https://arxiv.org/abs/2408.05246", "authors": "Ferdinando Fioretto, Diptangshu Sen, Juba Ziani", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "pdf_url": "https://arxiv.org/pdf/2408.05246", "relevancy_score": 6, "reasons_for_match": "This paper investigates the impact of differentially private data release on bias and unfairness in network information sharing, which is somewhat relevant to my interest in privacy and fairness in AI applications."}]