[{"title": "GPT-3 Powered Information Extraction for Building Robust Knowledge Bases", "abstract": "This work uses the state-of-the-art language model GPT-3 to offer a novel method of information extraction for knowledge base development. The suggested method attempts to solve the difficulties associated with obtaining relevant entities and relationships from unstructured text in order to extract structured information. We conduct experiments on a huge corpus of text from diverse fields to assess the performance of our suggested technique. The evaluation measures, which are frequently employed in information extraction tasks, include precision, recall, and F1-score. The findings demonstrate that GPT-3 can be used to efficiently and accurately extract pertinent and correct information from text, hence increasing the precision and productivity of knowledge base creation. We also assess how well our suggested approach performs in comparison to the most advanced information extraction techniques already in use. The findings show that by utilizing only a small number of instances in in-context learning, our suggested strategy yields competitive outcomes with notable savings in terms of data annotation and engineering expense. Additionally, we use our proposed method to retrieve Biomedical information, demonstrating its practicality in a real-world setting. All things considered, our suggested method offers a viable way to overcome the difficulties involved in obtaining structured data from unstructured text in order to create knowledge bases. It can greatly increase the precision and effectiveness of information extraction, which is necessary for many applications including chatbots, recommendation engines, and question-answering systems.", "url": "https://arxiv.org/abs/2408.04641", "authors": "Ritabrata Roy Choudhury, Soumik Dey", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "pdf_url": "https://arxiv.org/pdf/2408.04641", "relevancy_score": "9", "reasons_for_match": "This paper explores the use of GPT-3, a state-of-the-art language model, for information extraction and knowledge base development, which aligns with your interest in infrastructure improvements of AI systems."}, {"title": "Knowledge AI: Fine-tuning NLP Models for Facilitating Scientific Knowledge Extraction and Understanding", "abstract": "This project investigates the efficacy of Large Language Models (LLMs) in understanding and extracting scientific knowledge across specific domains and to create a deep learning framework: Knowledge AI. As a part of this framework, we employ pre-trained models and fine-tune them on datasets in the scientific domain. The models are adapted for four key Natural Language Processing (NLP) tasks: summarization, text generation, question answering, and named entity recognition. Our results indicate that domain-specific fine-tuning significantly enhances model performance in each of these tasks, thereby improving their applicability for scientific contexts. This adaptation enables non-experts to efficiently query and extract information within targeted scientific fields, demonstrating the potential of fine-tuned LLMs as a tool for knowledge discovery in the sciences.", "url": "https://arxiv.org/abs/2408.04651", "authors": "Balaji Muralidharan, Hayden Beadles, Reza Marzban, Kalyan Sashank Mupparaju", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "pdf_url": "https://arxiv.org/pdf/2408.04651", "relevancy_score": 9, "reasons_for_match": "This paper explores the fine-tuning of NLP models for scientific knowledge extraction, which aligns with the interest in infrastructure improvements for AI systems."}, {"title": "Strong and weak alignment of large language models with human values", "abstract": "Minimizing negative impacts of Artificial Intelligent (AI) systems on human societies without human supervision requires them to be able to align with human values. However, most current work only addresses this issue from a technical point of view, e.g., improving current methods relying on reinforcement learning from human feedback, neglecting what it means and is required for alignment to occur. Here, we propose to distinguish strong and weak value alignment. Strong alignment requires cognitive abilities (either human-like or different from humans) such as understanding and reasoning about agents' intentions and their ability to causally produce desired effects. We argue that this is required for AI systems like large language models (LLMs) to be able to recognize situations presenting a risk that human values may be flouted. To illustrate this distinction, we present a series of prompts showing ChatGPT's, Gemini's and Copilot's failures to recognize some of these situations. We moreover analyze word embeddings to show that the nearest neighbors of some human values in LLMs differ from humans' semantic representations. We then propose a new thought experiment that we call \"the Chinese room with a word transition dictionary\", in extension of John Searle's famous proposal. We finally mention current promising research directions towards a weak alignment, which could produce statistically satisfying answers in a number of common situations, however so far without ensuring any truth value.", "url": "https://arxiv.org/abs/2408.04655", "authors": "Mehdi Khamassi, Marceau Nahon, Raja Chatila", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "pdf_url": "https://arxiv.org/pdf/2408.04655", "relevancy_score": "9", "reasons_for_match": "The paper explores the alignment of large language models with human values, which is relevant to understanding the ethical implications of AI systems in my research interests."}, {"title": "Chain of Stance: Stance Detection with Large Language Models", "abstract": "Stance detection is an active task in natural language processing (NLP) that aims to identify the author's stance towards a particular target within a text. Given the remarkable language understanding capabilities and encyclopedic prior knowledge of large language models (LLMs), how to explore the potential of LLMs in stance detection has received significant attention. Unlike existing LLM-based approaches that focus solely on fine-tuning with large-scale datasets, we propose a new prompting method, called \\textit{Chain of Stance} (CoS). In particular, it positions LLMs as expert stance detectors by decomposing the stance detection process into a series of intermediate, stance-related assertions that culminate in the final judgment. This approach leads to significant improvements in classification performance. We conducted extensive experiments using four SOTA LLMs on the SemEval 2016 dataset, covering the zero-shot and few-shot learning setups. The results indicate that the proposed method achieves state-of-the-art results with an F1 score of 79.84 in the few-shot setting.", "url": "https://arxiv.org/abs/2408.04649", "authors": "Junxia Ma, Changjiang Wang, Hanwen Xing, Dongming Zhao, Yazhou Zhang", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "pdf_url": "https://arxiv.org/pdf/2408.04649", "relevancy_score": "8", "reasons_for_match": "This paper explores the use of large language models for stance detection, a task in natural language processing, which aligns with your interest in AI infrastructure improvements."}, {"title": "Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools", "abstract": "Objective: This study aims to develop and validate an evaluation framework to ensure the safety and reliability of mental health chatbots, which are increasingly popular due to their accessibility, human-like interactions, and context-aware support. Materials and Methods: We created an evaluation framework with 100 benchmark questions and ideal responses, and five guideline questions for chatbot responses. This framework, validated by mental health experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation methods explored included large language model (LLM)-based scoring, an agentic approach using real-time data, and embedding models to compare chatbot responses against ground truth standards. Results: The results highlight the importance of guidelines and ground truth for improving LLM evaluation accuracy. The agentic method, dynamically accessing reliable information, demonstrated the best alignment with human assessments. Adherence to a standardized, expert-validated framework significantly enhanced chatbot response safety and reliability. Discussion: Our findings emphasize the need for comprehensive, expert-tailored safety evaluation metrics for mental health chatbots. While LLMs have significant potential, careful implementation is necessary to mitigate risks. The superior performance of the agentic approach underscores the importance of real-time data access in enhancing chatbot reliability. Conclusion: The study validated an evaluation framework for mental health chatbots, proving its effectiveness in improving safety and reliability. Future work should extend evaluations to accuracy, bias, empathy, and privacy to ensure holistic assessment and responsible integration into healthcare. Standardized evaluations will build trust among users and professionals, facilitating broader adoption and improved mental health support through technology.", "url": "https://arxiv.org/abs/2408.04650", "authors": "Jung In Park, Mahyar Abbasian, Iman Azimi, Dawn Bounds, Angela Jun, Jaesu Han, Robert McCarron, Jessica Borelli, Jia Li, Mona Mahmoudi, Carmen Wiedenhoeft, Amir Rahmani", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "pdf_url": "https://arxiv.org/pdf/2408.04650", "relevancy_score": 8, "reasons_for_match": "This paper focuses on the evaluation and safety of chatbots, which aligns with the interest in infrastructure improvements for AI systems."}, {"title": "XMainframe: A Large Language Model for Mainframe Modernization", "abstract": "Mainframe operating systems, despite their inception in the 1940s, continue to support critical sectors like finance and government. However, these systems are often viewed as outdated, requiring extensive maintenance and modernization. Addressing this challenge necessitates innovative tools that can understand and interact with legacy codebases. To this end, we introduce XMainframe, a state-of-the-art large language model (LLM) specifically designed with knowledge of mainframe legacy systems and COBOL codebases. Our solution involves the creation of an extensive data collection pipeline to produce high-quality training datasets, enhancing XMainframe's performance in this specialized domain. Additionally, we present MainframeBench, a comprehensive benchmark for assessing mainframe knowledge, including multiple-choice questions, question answering, and COBOL code summarization. Our empirical evaluations demonstrate that XMainframe consistently outperforms existing state-of-the-art LLMs across these tasks. Specifically, XMainframe achieves 30% higher accuracy than DeepSeek-Coder on multiple-choice questions, doubles the BLEU score of Mixtral-Instruct 8x7B on question answering, and scores six times higher than GPT-3.5 on COBOL summarization. Our work highlights the potential of XMainframe to drive significant advancements in managing and modernizing legacy systems, thereby enhancing productivity and saving time for software developers.", "url": "https://arxiv.org/abs/2408.04660", "authors": "Anh T. V. Dau, Hieu Trung Dao, Anh Tuan Nguyen, Hieu Trung Tran, Phong X. Nguyen, Nghi D. Q. Bui", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "pdf_url": "https://arxiv.org/pdf/2408.04660", "relevancy_score": "8", "reasons_for_match": "The paper introduces XMainframe, a large language model specifically designed for mainframe modernization, which aligns with my interest in infrastructure improvements for AI systems."}, {"title": "Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course", "abstract": "This study evaluates the performance of Large Language Models (LLMs) as an Artificial Intelligence-based tutor for a university course. In particular, different advanced techniques are utilized, such as prompt engineering, Retrieval-Augmented-Generation (RAG), and fine-tuning. We assessed the different models and applied techniques using common similarity metrics like BLEU-4, ROUGE, and BERTScore, complemented by a small human evaluation of helpfulness and trustworthiness. Our findings indicate that RAG combined with prompt engineering significantly enhances model responses and produces better factual answers. In the context of education, RAG appears as an ideal technique as it is based on enriching the input of the model with additional information and material which usually is already present for a university course. Fine-tuning, on the other hand, can produce quite small, still strong expert models, but poses the danger of overfitting. Our study further asks how we measure performance of LLMs and how well current measurements represent correctness or relevance? We find high correlation on similarity metrics and a bias of most of these metrics towards shorter responses. Overall, our research points to both the potential and challenges of integrating LLMs in educational settings, suggesting a need for balanced training approaches and advanced evaluation frameworks.", "url": "https://arxiv.org/abs/2408.04645", "authors": "Sebastian Kahl, Felix L\u00f6ffler, Martin Maciol, Fabian Ridder, Marius Schmitz, Jennifer Spanagel, Jens Wienkamp, Christopher Burgahn, Malte Schilling", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Robotics (cs.RO)", "pdf_url": "https://arxiv.org/pdf/2408.04645", "relevancy_score": "7", "reasons_for_match": "This paper evaluates the impact of advanced LLM techniques on AI-based tutors for a university course, which falls under your interest in AI and education."}, {"title": "Leveraging Large Language Models with Chain-of-Thought and Prompt Engineering for Traffic Crash Severity Analysis and Inference", "abstract": "Harnessing the power of Large Language Models (LLMs), this study explores the use of three state-of-the-art LLMs, specifically GPT-3.5-turbo, LLaMA3-8B, and LLaMA3-70B, for crash severity inference, framing it as a classification task. We generate textual narratives from original traffic crash tabular data using a pre-built template infused with domain knowledge. Additionally, we incorporated Chain-of-Thought (CoT) reasoning to guide the LLMs in analyzing the crash causes and then inferring the severity. This study also examine the impact of prompt engineering specifically designed for crash severity inference. The LLMs were tasked with crash severity inference to: (1) evaluate the models' capabilities in crash severity analysis, (2) assess the effectiveness of CoT and domain-informed prompt engineering, and (3) examine the reasoning abilities with the CoT framework. Our results showed that LLaMA3-70B consistently outperformed the other models, particularly in zero-shot settings. The CoT and Prompt Engineering techniques significantly enhanced performance, improving logical reasoning and addressing alignment issues. Notably, the CoT offers valuable insights into LLMs' reasoning processes, unleashing their capacity to consider diverse factors such as environmental conditions, driver behavior, and vehicle characteristics in severity analysis and inference.", "url": "https://arxiv.org/abs/2408.04652", "authors": "Hao Zhen, Yucheng Shi, Yongcan Huang, Jidong J. Yang, Ninghao Liu", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "pdf_url": "https://arxiv.org/pdf/2408.04652", "relevancy_score": 7, "reasons_for_match": "This paper leverages large language models for crash severity analysis, which aligns with the interest in infrastructure improvements for AI systems."}, {"title": "PLUGH: A Benchmark for Spatial Understanding and Reasoning in Large Language Models", "abstract": "We present PLUGH (this https URL), a modern benchmark that currently consists of 5 tasks, each with 125 input texts extracted from 48 different games and representing 61 different (non-isomorphic) spatial graphs to assess the abilities of Large Language Models (LLMs) for spatial understanding and reasoning. Our evaluation of API-based and open-sourced LLMs shows that while some commercial LLMs exhibit strong reasoning abilities, open-sourced competitors can demonstrate almost the same level of quality; however, all models still have significant room for improvement. We identify typical reasons for LLM failures and discuss possible ways to deal with them. Datasets and evaluation code are released (this https URL).", "url": "https://arxiv.org/abs/2408.04648", "authors": "Alexey Tikhonov", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "pdf_url": "https://arxiv.org/pdf/2408.04648", "relevancy_score": "6", "reasons_for_match": "This paper presents a benchmark for spatial understanding and reasoning in large language models, which may be relevant to your interest in AI infrastructure improvements."}, {"title": "Batching BPE Tokenization Merges", "abstract": "The Byte Pair Encoding algorithm can be safely batched to merge hundreds of pairs of tokens at a time when building up a tokenizer's vocabulary. This technique combined with reducing the memory footprint of text used in vocabulary training make it feasible to train a high quality tokenizer on a basic laptop. This paper presents BatchBPE, an open-source pure Python implementation of these concepts, with the goal of making experimenting with new tokenization strategies more accessible especially in compute- and memory-constrained contexts. BatchBPE's usefulness and malleability are demonstrated through the training of several token vocabularies to explore the batch merging process and experiment with preprocessing a stop word list and ignoring the least common text chunks in a dataset. Resultant encoded lengths of texts are used as a basic evaluation metric.", "url": "https://arxiv.org/abs/2408.04653", "authors": "Alexander P. Morgan", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "pdf_url": "https://arxiv.org/pdf/2408.04653", "relevancy_score": 4, "reasons_for_match": "This paper focuses on tokenization strategies and vocabulary training, which is more related to model improvements rather than infrastructure improvements."}]